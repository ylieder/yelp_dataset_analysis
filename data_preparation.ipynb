{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "This notebook can be used to prepare the datasets used for the gender prediction task. Datasets are created for different numbers of reviews per user (e.g. a dataset where all samples consist of 5 reviews of one user) and each dataset is split into a training and a test subset.\n",
    "\n",
    "### The dataset are created as follows:\n",
    "- Read review data from Yelp JSON files and group by users\n",
    "- Guess user gender based on children names list\n",
    "- Skip all users with unknown/both gender\n",
    "- Sanitize reviews (remove punctation and special character)\n",
    "- Shuffle data (users)\n",
    "- Select balanced (same number of M and F samples) training and test data sets (pick only users with at least required number of reviews)\n",
    "- Serialize data\n",
    "\n",
    "### The resulting datasets:\n",
    "- `all`: A balanced subset of 300,000 samples, for each sample (user) the original number of reviews is kept (representative for whole dataset)\n",
    "- `n = 1, 2, 5, 10, 20`: A balanced subset of max. 300,000 samples, only samples with at least `n` reviews are picked and exactly `n` random reviews are selected from each sample\n",
    "\n",
    "Each dataset is split into 90% training and 10% test samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "from GenderGuesser import GenderGuesser, Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('data')\n",
    "yelp_dataset_dir = data_dir / 'yelp_dataset'\n",
    "name_list_file = data_dir / 'names/yob2019.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = 300_000\n",
    "train_size = 0.9\n",
    "number_of_reviews = ['all', 1, 2, 5, 10, 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize_review(text):\n",
    "    sanitized_review = re.sub(r'[\\s,+&%$!?.*-]+', ' ', text)\n",
    "    sanitized_review = re.sub(r'(\\s|^)\\d+(\\.\\d+)?(\\s|$)', ' ', sanitized_review)\n",
    "    sanitized_review = sanitized_review.lower()\n",
    "    return sanitized_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(yelp_dataset_dir, name_list_file):\n",
    "    \"\"\"\n",
    "    Reads the Yelp user and review JSON files and extracts the reviews of all users whose names are either male or\n",
    "    female.\n",
    "\n",
    "    :param yelp_dataset_dir: Path to yelp dataset JSON files .\n",
    "    :return: List of tuples (gender, reviews) for each user with a male or female name.\n",
    "    \"\"\"\n",
    "    gender_guesser = GenderGuesser(name_list_file)\n",
    "    data = dict()\n",
    "\n",
    "    start = timer()\n",
    "    with open(f'{yelp_dataset_dir}/yelp_academic_dataset_user.json', 'r') as fd:\n",
    "        for line in fd:\n",
    "            record = json.loads(line)\n",
    "\n",
    "            gender = gender_guesser.guess(record['name'])\n",
    "            if gender in (Gender.M, Gender.F):\n",
    "                data[record['user_id']] = (gender, [])\n",
    "\n",
    "    with open(f'{yelp_dataset_dir}/yelp_academic_dataset_review.json', 'r') as fd:\n",
    "        for line in fd:\n",
    "            record = json.loads(line)\n",
    "\n",
    "            if record['user_id'] in data:\n",
    "                data[record['user_id']][1].append(sanitize_review(record['text']))\n",
    "\n",
    "    end = timer()\n",
    "    print(f\"Read JSON data in {timedelta(seconds=end-start)}\")\n",
    "\n",
    "    return list(data.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read JSON data in 0:08:23.352105\n"
     ]
    }
   ],
   "source": [
    "data = read_data(yelp_dataset_dir, name_list_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "random.seed(seed)\n",
    "random.shuffle(data)\n",
    "for i in range(len(data)):\n",
    "    random.shuffle(data[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_f = [x for x in data if x[0] == Gender.F]\n",
    "data_m = [x for x in data if x[0] == Gender.M]\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all: Created dataset with 270000 training  and 30000 test samples \n",
      "1: Created dataset with 270000 training  and 30000 test samples \n",
      "2: Created dataset with 270000 training  and 30000 test samples \n",
      "5: Created dataset with 132503 training  and 14723 test samples \n",
      "10: Created dataset with 56871 training  and 6319 test samples \n",
      "20: Created dataset with 22140 training  and 2460 test samples \n"
     ]
    }
   ],
   "source": [
    "dataset_dir = data_dir / 'datasets'\n",
    "dataset_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for n in number_of_reviews:\n",
    "    if n == 'all':\n",
    "        n_reviews = max([len(reviews) for _, reviews in data_f] + [len(reviews) for _, reviews in data_m])\n",
    "    else:\n",
    "        n_reviews = n\n",
    "        \n",
    "    dataset_f = [\n",
    "        (gender, reviews[:n_reviews]) for gender, reviews in data_f if len(reviews) >= n_reviews or n == 'all'\n",
    "    ][:int(dataset_size/2)] \n",
    "    dataset_m = [\n",
    "        (gender, reviews[:n_reviews]) for gender, reviews in data_m if len(reviews) >= n_reviews or n == 'all'\n",
    "    ][:int(dataset_size/2)]\n",
    "    \n",
    "    size = min(len(dataset_f), len(dataset_m))\n",
    "    \n",
    "    dataset = dataset_f[:size] + dataset_m[:size]\n",
    "    random.shuffle(dataset)\n",
    "    \n",
    "    with open(dataset_dir / f'dataset_{n}_train.pkl', 'wb') as fd:\n",
    "        pickle.dump(dataset[:int(train_size * len(dataset))], fd)\n",
    "                            \n",
    "    with open(dataset_dir / f'dataset_{n}_test.pkl', 'wb') as fd:\n",
    "        pickle.dump(dataset[int(train_size * len(dataset)):], fd)\n",
    "                            \n",
    "    print(\n",
    "        f\"{n}: Created dataset with {int(train_size * len(dataset))} training \",\n",
    "        f\"and {len(dataset) - int(train_size * len(dataset))} test samples \",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yelp-dataset",
   "language": "python",
   "name": "yelp-dataset"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
